{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7978b54c",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f910a9",
   "metadata": {},
   "source": [
    "### by ReDay Zarra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7084873",
   "metadata": {},
   "source": [
    "This is **simply a template to get you started** with data preprocessing. The libraries are all ready-to-go, you just have to ensure you input the right parameters. I will leave hints for how to configure the code to your needs so you can use this as reference or to start a new project.\n",
    "\n",
    "If you would like to **learn about data preprocessing**, please visit: [Data Preprocessing Theory](https://www.redaysblog.com/machine-learning/data-preprocessing)\n",
    "\n",
    "If you want an **explanation for the code** in detail, please visit: [Data Preprocessing - Code](https://github.com/redayzarra/ml-data-preprocessing/blob/master/Data_Preprocessing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfc5ee",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72033035",
   "metadata": {},
   "source": [
    "Importing the necessary libraries and modules we need to start preprocessing \n",
    "our data. **Pandas** is a library used for data frame manipulations. **NumPy** is a package used for numerical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19f52252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f38809",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defdf3f",
   "metadata": {},
   "source": [
    "To make sure you do this correctly, make sure the **name of our data file matches** the one inside the .read_csv() function. I am also assuming that your **dependent variable**, the thing you want to predict, **is in the last column**. If that is not the case then change the \"-1\" to the index of our dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0900e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('YOUR_DATA.csv')\n",
    "\n",
    "# X are features, y is the dependent variable.\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b9d455",
   "metadata": {},
   "source": [
    "## Addressing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d44a92",
   "metadata": {},
   "source": [
    "Make sure to **change the \"0\" in the brackets to the indices of the columns** you want to address the missing values in. Currently the index 0 is applying the mean imputer for the first column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(X[: , 0])\n",
    "X[: , 0]  = imputer.transform(X[: , 0])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d1612",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ad364",
   "metadata": {},
   "source": [
    "Utilize this step **if you have categorical data** or if your dependent variable are classes (in words). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2359ea4",
   "metadata": {},
   "source": [
    "### Encoding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9469921",
   "metadata": {},
   "source": [
    "Make sure to **change the \"0\" in the brackets to the column** containing the categorical data you wish to encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15407725",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [0])], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(transformer.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1b316",
   "metadata": {},
   "source": [
    "### Encoding the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefd9f9",
   "metadata": {},
   "source": [
    "You should **only use this if your dependent variable is categorical data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfc712",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8847a971",
   "metadata": {},
   "source": [
    "**Adjust the testing set size to your liking** by changing the \"0.2\" to whatever ratio you would like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb94ecf",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f26475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f554f",
   "metadata": {},
   "source": [
    "Make sure to a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[: , 0] = scaler.fit_transform(X_train[: , 0])\n",
    "X_test[: , 0] = scaler.fit_transform(X_test[: , 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
