{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2976d0a3",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfb658",
   "metadata": {},
   "source": [
    "### by ReDay Zarra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae71d6dc",
   "metadata": {},
   "source": [
    "Data preprocessing is about **preparing data for analysis** by cleaning, transforming, and organizing it. This step is crucial for any machine learning or data analysis as it helps to ensure that the data is accurate, consistent, and comprehensive. Data preprocessing includes tasks such as handling missing values, removing outliers, normalizing data, and encoding categorical variables. The goal of data preprocessing is to **make the data as clean and usable** as possible, so that it can be used for further analysis and modeling.\n",
    "\n",
    "The three major steps of data preprocessing includes:\n",
    "\n",
    "1. Importing the necessary libraries\n",
    "\n",
    "2. Importing the dataset\n",
    "\n",
    "3. Addressing missing data\n",
    "\n",
    "4. Encoding categorical data\n",
    "\n",
    "5. Splitting the dataset\n",
    "\n",
    "6. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4780b2",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb075469",
   "metadata": {},
   "source": [
    "Importing the necessary libraries and modules we need to start preprocessing \n",
    "our data. **Pandas** is a library used for data frame manipulations. **NumPy** is a package used for numerical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7891b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eeb439",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dc895",
   "metadata": {},
   "source": [
    "Importing the dataset requires us to use the **Pandas library which will import the dataset** in a new variable. Then we have to create the matrix of features and then the dependent variable vector. The features are the columns with which you will predict the final decision (dependent variable). So, the dependent variable is really what you want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66fd532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "X = dataset.iloc[: , :-1].values\n",
    "y = dataset.iloc[: , -1].values\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adda665",
   "metadata": {},
   "source": [
    "> Pandas reads the dataset and **creates a data frame** which is **stored in the variable dataset**. The **.iloc() function** means locating indices and **identifies the data we want to target**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05951c2",
   "metadata": {},
   "source": [
    "## Addressing missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8907773",
   "metadata": {},
   "source": [
    "Our dataset has missing data and values for some of the features,\n",
    "which can cause errors in our machine learning models. To address that, there\n",
    "are some options:\n",
    "\n",
    "  1. Ignoring the missing data by simply **removing** missing data\n",
    "  \n",
    "  2. **Replacing** the missing data with the average of the column\n",
    "\n",
    "**Scikit-Learn** is a data science library with a lot of data\n",
    "preprocessing tools that aid us in replacing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28beb7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240553cc",
   "metadata": {},
   "source": [
    "> Uses the SimpleImputer class to target the missing values with the **missing_values** parameter. The **strategy** parameter specifies that we want to replace it with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409d36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(X[: , 1:3])\n",
    "X[: , 1:3]  = imputer.transform(X[: , 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77335ab0",
   "metadata": {},
   "source": [
    "> The .fit() method from the imputer applies our SimpleImputer to the data specified. We then use the .transform() method to change the original data to the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad3d85",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c532a8",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c326604",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
