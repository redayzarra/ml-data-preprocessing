{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75b86ef",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b0e48",
   "metadata": {},
   "source": [
    "### by ReDay Zarra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080b386",
   "metadata": {},
   "source": [
    "Data preprocessing is about **preparing data for analysis** by cleaning, transforming, and organizing it. This step is crucial for any machine learning or data analysis as it helps to ensure that the data is accurate, consistent, and comprehensive. Data preprocessing includes tasks such as handling missing values, removing outliers, normalizing data, and encoding categorical variables. The goal of data preprocessing is to **make the data as clean and usable** as possible, so that it can be used for further analysis and modeling.\n",
    "\n",
    "The three major steps of data preprocessing includes:\n",
    "\n",
    "1. Importing the necessary libraries\n",
    "\n",
    "2. Importing the dataset\n",
    "\n",
    "3. Addressing missing data\n",
    "\n",
    "4. Encoding categorical data\n",
    "\n",
    "5. Splitting the dataset\n",
    "\n",
    "6. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8647b",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a881c",
   "metadata": {},
   "source": [
    "Importing the necessary libraries and modules we need to start preprocessing \n",
    "our data. **Pandas** is a library used for data frame manipulations. **NumPy** is a package used for numerical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6f10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ef5ef",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c82ccb",
   "metadata": {},
   "source": [
    "Importing the dataset requires us to use the **Pandas library which will import the dataset** in a new variable. Then we have to create the matrix of features and then the dependent variable vector. The features are the columns with which you will predict the final decision (dependent variable). So, the dependent variable is really what you want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc273b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "X = dataset.iloc[: , :-1].values\n",
    "Y = dataset.iloc[: , -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f8059",
   "metadata": {},
   "source": [
    "## Addressing missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53946d1",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d3a947",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81553ec5",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
