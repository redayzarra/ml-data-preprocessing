{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0cff26c",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9e8f73",
   "metadata": {},
   "source": [
    "### by ReDay Zarra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9471cfef",
   "metadata": {},
   "source": [
    "This is **simply a template to get you started** with data preprocessing. The libraries are all ready-to-go, you just have to ensure you input the right parameters. I will leave hints for how to configure the code to your needs so you can use this as reference or to start a new project.\n",
    "\n",
    "If you would like to **learn about data preprocessing**, please visit: [Data Preprocessing Theory](https://www.redaysblog.com/machine-learning/data-preprocessing)\n",
    "\n",
    "If you want an **explanation for the code** in detail, please visit: [Data Preprocessing - Code](https://github.com/redayzarra/ml-data-preprocessing/blob/master/Data_Preprocessing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3cd080",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12267f50",
   "metadata": {},
   "source": [
    "Importing the necessary libraries and modules we need to start preprocessing \n",
    "our data. **Pandas** is a library used for data frame manipulations. **NumPy** is a package used for numerical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0600b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845125ab",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ddb5d9",
   "metadata": {},
   "source": [
    "To make sure you do this correctly, make sure the **name of our data file matches** the one inside the .read_csv() function. I am also assuming that your **dependent variable**, the thing you want to predict, **is in the last column**. If that is not the case then change the \"-1\" to the index of our dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc107f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = pd.read_csv('YOUR_DATA.csv')\n",
    "\n",
    "# X are features, y is the dependent variable.\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1b8771",
   "metadata": {},
   "source": [
    "## Addressing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3534706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe767e93",
   "metadata": {},
   "source": [
    "Make sure to **change the \"0\" in the brackets to the indices of the columns** you want to address the missing values in. Currently the index 0 is applying the mean imputer for the first column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6440bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(X[: , 0])\n",
    "X[: , 0]  = imputer.transform(X[: , 0])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53e86d",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70757a",
   "metadata": {},
   "source": [
    "Utilize this step **if you have categorical data** or if your dependent variable are classes (in words). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8d408",
   "metadata": {},
   "source": [
    "### Encoding the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8956496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21b792",
   "metadata": {},
   "source": [
    "Make sure to **change the \"0\" in the brackets to the column** containing the categorical data you wish to encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [0])], remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedeaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(transformer.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d971f6cf",
   "metadata": {},
   "source": [
    "### Encoding the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c097b",
   "metadata": {},
   "source": [
    "You should **only use this if your dependent variable is categorical data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b5e754",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42cc7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c37d9",
   "metadata": {},
   "source": [
    "**Adjust the testing set size to your liking** by changing the \"0.2\" to whatever ratio you would like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda74d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd5524",
   "metadata": {},
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7dec01",
   "metadata": {},
   "source": [
    "Make sure to **adjust the \"0\" in the brackets to the indices of the columns** that you would like to scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5309fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[: , 0] = scaler.fit_transform(X_train[: , 0])\n",
    "X_test[: , 0] = scaler.fit_transform(X_test[: , 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
